{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from keras.models import model_from_json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "def save_model(model, name):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"{}.json\".format(name), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"{}.h5\".format(name))\n",
    "    print(\"Model {} saved!\".format(name))\n",
    "    \n",
    "def load_model(name):\n",
    "    json_file = open('{}.json'.format(name), 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"{}.h5\".format(name))\n",
    "    return loaded_model\n",
    "\n",
    "# static_model = load_model(\"static_model\")\n",
    "\n",
    "\n",
    "dynamic_gestures_labesl_dict = {0: \"stop\",\n",
    "                                1: \"come_on\",\n",
    "                                2: \"go_away\",\n",
    "                                3: \"look_at_me\",\n",
    "                                4: \"other\"}\n",
    "\n",
    "gestures_to_num_dict = dict(zip(dynamic_gestures_labesl_dict.values(), dynamic_gestures_labesl_dict.keys()))\n",
    "\n",
    "full_data = []\n",
    "full_labels = []\n",
    "\n",
    "for gesture in gestures_to_num_dict:\n",
    "    fname = \"{}.npy\".format(gesture)\n",
    "    data = np.load(fname, allow_pickle=True)\n",
    "    label = gestures_to_num_dict[gesture]\n",
    "    for single_data in data:\n",
    "        if len(single_data) == 63:\n",
    "            full_data.append(np.array(single_data[5:]))\n",
    "            full_labels.append(label)\n",
    "    \n",
    "full_data = np.array(full_data)\n",
    "full_labels = np.array(full_labels)\n",
    "\n",
    "\n",
    "labels_dict = {\"hands_down\": 0,\n",
    "               \"stop\": 1,\n",
    "               \"hands_up\": 2,\n",
    "               \"hands_up_small\": 3,\n",
    "               \"hands_down_small\": 4,\n",
    "               \"hads_down_up\": 5,\n",
    "               \"hands_to_sides\": 6}\n",
    "\n",
    "decode_labels_dict = {val: key for key, val in labels_dict.items()}\n",
    "\n",
    "def get_static_gestures_list(features_sequence):\n",
    "    static_gestures_numbers = []\n",
    "    for features in features_sequence:\n",
    "        data = np.array([features])\n",
    "        prediction_result = np.argmax(static_model.predict(data))\n",
    "        static_gestures_numbers.append(prediction_result)\n",
    "    return static_gestures_numbers\n",
    "\n",
    "\n",
    "static_gestures_sequence_lists = []\n",
    "\n",
    "for data in full_data:\n",
    "    static_gestures_sequence = get_static_gestures_list(data)\n",
    "    data = np.array([static_gestures_sequence])\n",
    "    data = np.hstack(data)\n",
    "    static_gestures_sequence_lists.append(data)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(static_gestures_sequence_lists, full_labels, stratify=full_labels,\n",
    "                                                    test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(704, 58, 1)\n",
    "X_test = X_test.reshape(302, 58, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### X_train[0].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "input_shape=(None, X_train[0].shape[-1])\n",
    "\n",
    "conv_1d_model = Sequential()\n",
    "conv_1d_model.add(layers.Conv1D(58, 5, activation='sigmoid', input_shape=input_shape))\n",
    "# conv_1d_model.add(layers.MaxPooling1D(3))\n",
    "conv_1d_model.add(layers.Conv1D(32, 5, activation='sigmoid'))\n",
    "conv_1d_model.add(layers.MaxPooling1D(3))\n",
    "conv_1d_model.add(layers.Conv1D(32, 5, activation='sigmoid'))#6.4. Обработка последовательностей с помощью сверточных нейронных сетей   265\n",
    "conv_1d_model.add(layers.GlobalMaxPooling1D())\n",
    "conv_1d_model.add(layers.Dense(5, activation=\"softmax\"))\n",
    "conv_1d_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "history_1d = conv_1d_model.fit(X_train,y_train, epochs=500, validation_data=(np.array(X_test), np.array(y_test)), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_1d.history[\"acc\"]\n",
    "val_acc = history_1d.history[\"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "rnn_model = Sequential()\n",
    "\n",
    "# rnn_model.add(Embedding(max_features, 32))\n",
    "rnn_model.add(SimpleRNN(58, input_shape=input_shape))\n",
    "rnn_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "rnn_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "history_rnn = rnn_model.fit(X_train,y_train, epochs=500, validation_data=(np.array(X_test), np.array(y_test)), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_acc = history_rnn.history[\"acc\"]\n",
    "rnn_val_acc = history_rnn.history[\"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(rnn_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(rnn_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "lstm_model = Sequential()\n",
    "\n",
    "# lstm_model.add(Embedding(max_features, 32))\n",
    "lstm_model.add(LSTM(58, input_shape=input_shape))\n",
    "lstm_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "lstm_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "history_lstm = lstm_model.fit(X_train,y_train, epochs=500, validation_data=(np.array(X_test), np.array(y_test)), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_acc = history_lstm.history[\"acc\"]\n",
    "lstm_val_acc = history_lstm.history[\"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(lstm_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(lstm_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "gru_model = Sequential()\n",
    "gru_model.add(layers.GRU(58,input_shape=input_shape))\n",
    "\n",
    "gru_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "gru_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "history_gru = gru_model.fit(X_train,y_train, epochs=500, validation_data=(np.array(X_test), np.array(y_test)), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_acc = history_gru.history[\"acc\"]\n",
    "gru_val_acc = history_gru.history[\"val_acc\"]\n",
    "np.argmax(gru_val_acc)\n",
    "np.max(gru_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(gru_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(gru_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "gru2_model = Sequential()\n",
    "gru2_model.add(layers.GRU(58,\n",
    "                            dropout=0.1,\n",
    "                            recurrent_dropout=0.5,\n",
    "                            return_sequences=False,\n",
    "                            input_shape=input_shape))\n",
    "# gru2_model.add(layers.GRU(58), activation=\"sigmoid\")\n",
    "gru2_model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "gru2_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "history_gru2 = gru2_model.fit(X_train,y_train, epochs=500, validation_data=(np.array(X_test), np.array(y_test)), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru2_acc = history_gru2.history[\"acc\"]\n",
    "gru2_val_acc = history_gru2.history[\"val_acc\"]\n",
    "np.argmax(gru2_val_acc)\n",
    "np.max(gru2_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from src.PoseExtractor import PoseExtractor\n",
    "from src.data_processing.pose_utils import *\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "\n",
    "labels_dict = {\"hands_down\": 0,\n",
    "               \"stop\": 1,\n",
    "               \"hands_up\": 2,\n",
    "               \"hands_up_small\": 3,\n",
    "               \"hands_down_small\": 4,\n",
    "               \"hads_down_up\": 5,\n",
    "               \"hands_to_sides\": 6}\n",
    "\n",
    "decode_labels_dict = {val: key for key, val in labels_dict.items()}\n",
    "\n",
    "\n",
    "dynamic_gestures_labesl_dict = {0: \"stop\",\n",
    "                                1: \"come_on\",\n",
    "                                2: \"go_away\",\n",
    "                                3: \"look_at_me\",\n",
    "                                4: \"other\"}\n",
    "\n",
    "gestures_to_num_dict = dict(zip(dynamic_gestures_labesl_dict.values(), dynamic_gestures_labesl_dict.keys()))\n",
    "\n",
    "\n",
    "def save_model(model, name):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"{}.json\".format(name), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"{}.h5\".format(name))\n",
    "    print(\"Model {} saved!\".format(name))\n",
    "    \n",
    "def load_model(name):\n",
    "    json_file = open('{}.json'.format(name), 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"{}.h5\".format(name))\n",
    "    return loaded_model\n",
    "\n",
    "static_model = load_model(\"static_model\")\n",
    "dynamic_model = load_model(\"dynamic_model\")\n",
    "\n",
    "\n",
    "\n",
    "def get_biggest_pose(poses):\n",
    "    max_distance = -1\n",
    "    biggest_pose = None\n",
    "    if len(poses):\n",
    "        for pose in poses:\n",
    "            pose_key_point1 = pose.points[1]\n",
    "            pose_key_point2 = pose.points[8]\n",
    "            if all(pose_key_point1.int_xy) and all(pose_key_point2.int_xy):\n",
    "                distance = get_distance_between_points(pose_key_point1, pose_key_point2)\n",
    "                if distance >= max_distance:\n",
    "                    max_distance = distance\n",
    "                    biggest_pose = pose\n",
    "        return biggest_pose\n",
    "    \n",
    "    \n",
    "def find_distance(pt1, pt2):\n",
    "    return np.sqrt((pt2.x - pt1.x)**2 + (pt2.y - pt1.y)**2)\n",
    "\n",
    "    \n",
    "def new_extract_features(pose, central_point_idx, specific_points):\n",
    "    assert central_point_idx not in specific_points\n",
    "    \n",
    "    rescaled_pose = rescale_pose(pose)\n",
    "    central_point = rescaled_pose.points[central_point_idx]\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for current_points_idx in specific_points:\n",
    "        current_point = rescaled_pose.points[current_points_idx]\n",
    "\n",
    "        dx = central_point.x - current_point.x\n",
    "        dy = central_point.y - current_point.y\n",
    "    \n",
    "        features.append(dx)\n",
    "        features.append(dy)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "class FeaturesSequence():\n",
    "    \n",
    "    default_pose = 0\n",
    "    \n",
    "    def __init__(self, max_features_num):\n",
    "        self.__max_features_num = max_features_num\n",
    "        self.__features_sequence = [0] * self.__max_features_num\n",
    "    \n",
    "    def update_features_sequense(self, new_features):\n",
    "        if len(self.__features_sequence) >= self.__max_features_num:\n",
    "            self.__features_sequence = self.__features_sequence[1:]\n",
    "        self.__features_sequence.append(new_features)\n",
    "        \n",
    "    def get_vectorized_features(self):\n",
    "        return self.__features_to_vec(self.__features_sequence).reshape(1, -1)\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def features(self):\n",
    "        return self.__features_sequence\n",
    "    \n",
    "    @staticmethod\n",
    "    def __features_to_vec(features):\n",
    "        vectors = []\n",
    "        for f in features:\n",
    "            zeros = np.zeros((6))\n",
    "            zeros[f-1] = 1\n",
    "            vectors.append(zeros)\n",
    "        return np.array(vectors)\n",
    "    \n",
    "    \n",
    "capture = cv2.VideoCapture(0)\n",
    "pose_extractor = PoseExtractor()\n",
    "top_pose_points = [0, 2, 3, 4, 5, 6, 7, 8, 9, 12, 15, 16, 17, 18]\n",
    "\n",
    "features_seq = FeaturesSequence(58)\n",
    "\n",
    "while True:\n",
    "    ret, img = capture.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    poses = pose_extractor.extract_poses_from_image(img)\n",
    "    actual_pose =  get_biggest_pose(poses)\n",
    "    if actual_pose is not None:\n",
    "        features = new_extract_features(actual_pose, 1, top_pose_points)\n",
    "        gesture = static_model.predict(features.reshape(1, -1))\n",
    "        gesture = np.argmax(gesture)\n",
    "        str_gesture = decode_labels_dict[gesture]\n",
    "        \n",
    "        features_seq.update_features_sequense(gesture)\n",
    "#         features_seq.update_features_sequense(gesture)\n",
    "#         features_seq.update_features_sequense(gesture)\n",
    "#         features_seq.update_features_sequense(gesture)\n",
    "#         features_seq.update_features_sequense(gesture)\n",
    "#         features_seq.update_features_sequense(gesture)\n",
    "#         features_seq.update_features_sequense(gesture)\n",
    "        features_seq.update_features_sequense(gesture)\n",
    "\n",
    "\n",
    "#         vec = features_seq.get_vectorized_features()\n",
    "        \n",
    "#         print(vec)\n",
    "        features = np.array([np.array(features_seq.features).reshape(-1, 1)])\n",
    "#         print(features.shape)\n",
    "        dynamic_gesture = lstm_model.predict([features])\n",
    "        dynamic_gesture = np.argmax(dynamic_gesture)\n",
    "        str_dynamic_gesture = dynamic_gestures_labesl_dict[dynamic_gesture]\n",
    "        \n",
    "        cv2.putText(img, str_dynamic_gesture, (20, 20), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 3)\n",
    "        \n",
    "        \n",
    "        for point in actual_pose.points:\n",
    "            center = (int(point.x), int(point.y))\n",
    "            cv2.circle(img, center, 3, (0, 255, 255), -1)\n",
    "            \n",
    "    cv2.namedWindow(\"image\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"image\", img)\n",
    "    k = cv2.waitKey(10)\n",
    "    if k & 0xFF == 27:\n",
    "        break\n",
    "    \n",
    "    \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "max_features = 10000\n",
    "max_len = 500\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=\n",
    "max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "# x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "# x_test = sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_full_data = full_data.reshape(1006, 58*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "full_X_train, full_X_test, full_y_train, full_y_test = train_test_split(vec_full_data, full_labels, stratify=full_labels,\n",
    "                                                                        test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_train = full_X_train.reshape(704, 1624, 1)\n",
    "full_X_test = full_X_test.reshape(302, 1624, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# l = layers.Conv1D\n",
    "input_shape=(None, full_X_train[0].shape[-1])\n",
    "\n",
    "full_conv_1d_model = Sequential()\n",
    "full_conv_1d_model.add(layers.Conv1D(100, 5, activation='sigmoid', input_shape=input_shape))\n",
    "full_conv_1d_model.add(layers.Conv1D(100, 5, activation='sigmoid'))\n",
    "full_conv_1d_model.add(layers.MaxPooling1D(3))\n",
    "full_conv_1d_model.add(layers.Conv1D(100, 5, activation='sigmoid'))#6.4. Обработка последовательностей с помощью сверточных нейронных сетей   265\n",
    "full_conv_1d_model.add(layers.GlobalMaxPooling1D())\n",
    "full_conv_1d_model.add(layers.Dense(5, activation=\"softmax\"))\n",
    "full_conv_1d_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "full_history_1d = full_conv_1d_model.fit(full_X_train, full_y_train, epochs=100,\n",
    "                                         validation_data=(np.array(full_X_test), np.array(full_y_test)),\n",
    "                                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867549538612366"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(full_history_1d.history[\"val_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(full_history_1d.history[\"val_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
