{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hands_down\n",
      "stop\n",
      "hands_up\n",
      "hands_up_small\n",
      "hands_down_small\n",
      "hads_down_up\n",
      "hands_to_sides\n",
      "Loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "labels_dict = {\"hands_down\": 0,\n",
    "               \"stop\": 1,\n",
    "               \"hands_up\": 2,\n",
    "               \"hands_up_small\": 3,\n",
    "               \"hands_down_small\": 4,\n",
    "               \"hads_down_up\": 5,\n",
    "               \"hands_to_sides\": 6}\n",
    "\n",
    "data_list = []\n",
    "labels_list = []\n",
    "\n",
    "normalized_data_dir = \"database/static_gestures_with_pose_rescaling\"\n",
    "\n",
    "for folder in os.listdir(normalized_data_dir):\n",
    "    print(folder)\n",
    "    src_path = os.path.join(normalized_data_dir, folder)\n",
    "    for data_file_name in os.listdir(src_path):\n",
    "        full_data_file_path = os.path.join(src_path, data_file_name)\n",
    "        features = np.load(full_data_file_path)\n",
    "        if not any(np.isnan(features)):\n",
    "            data_list.append(features)\n",
    "            labels_list.append(labels_dict[folder])\n",
    "\n",
    "print(\"Loaded\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_list, labels_list, stratify=labels_list,\n",
    "                                                    test_size=0.3, random_state=42)\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(28, activation=\"relu\", input_shape=(28,)))\n",
    "\n",
    "model5.add(Dense(56, activation=\"relu\"))\n",
    "model5.add(Dense(28, activation=\"relu\"))\n",
    "\n",
    "\n",
    "model5.add(Dense(7, activation=\"softmax\"))\n",
    "model5.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "\n",
    "train_hist5 = model5.fit(np.array(X_train), np.array(y_train),\n",
    "                       epochs=33, batch_size=10,\n",
    "                       validation_data=(np.array(X_test), np.array(y_test)), \n",
    "                       verbose=False)\n",
    "\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(15, 5))\n",
    "# plt.plot(range(1, 158+1), train_hist5.history[\"acc\"])\n",
    "# plt.plot(range(1, 158+1), train_hist5.history[\"val_acc\"])\n",
    "# plt.legend([\"train accuracy\", \"validation accuracy\"])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat in X_test[:4]:\n",
    "    print(model5.predict(np.array([dat])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_data):\n",
    "    data = np.array([input_data])\n",
    "    prediction_result = np.argmax(model.predict(data))\n",
    "    print(prediction_result)\n",
    "    \n",
    "    labels_dict = {\"hands_down\": 0,\n",
    "               \"stop\": 1,\n",
    "               \"hands_up\": 2,\n",
    "               \"hands_up_small\": 3,\n",
    "               \"hands_down_small\": 4,\n",
    "               \"hads_down_up\": 5,\n",
    "               \"hands_to_sides\": 6}\n",
    "    \n",
    "    decode_labels_dict = {val: key for key, val in labels_dict.items()}\n",
    "    return decode_labels_dict[prediction_result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dat in X_test[:4]:\n",
    "    print(predict(model5, dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_labels_dict = {val: key for key, val in labels_dict.items()}\n",
    "\n",
    "\n",
    "    \n",
    "def predict(model, input_data):\n",
    "    data = np.array([input_data])\n",
    "    prediction_result = np.argmax(model.predict(data))\n",
    "    \n",
    "    labels_dict = {\"hands_down\": 0,\n",
    "               \"stop\": 1,\n",
    "               \"hands_up\": 2,\n",
    "               \"hands_up_small\": 3,\n",
    "               \"hands_down_small\": 4,\n",
    "               \"hads_down_up\": 5,\n",
    "               \"hands_to_sides\": 6}\n",
    "    \n",
    "    decode_labels_dict = {val: key for key, val in labels_dict.items()}\n",
    "    return decode_labels_dict[prediction_result]\n",
    "\n",
    "\n",
    "def rescale_values(values: np.array):\n",
    "    min_val = np.min(values)\n",
    "    max_val = np.max(values)\n",
    "    delta = max_val - min_val\n",
    "    \n",
    "    values -= min_val\n",
    "    values /= delta\n",
    "    values *= 100\n",
    "    values[values < 0] = 0\n",
    "    return values\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def rescale_pose(pose):\n",
    "    points = pose.points\n",
    "    xs = np.array([pt.x for pt in points])\n",
    "    ys = np.array([pt.y for pt in points])\n",
    "    xs = rescale_values(xs)\n",
    "    ys = rescale_values(ys)\n",
    "    rescaled_points = [Point(x, y) for x, y in zip(xs, ys)]\n",
    "    rescaled_pose = Pose(rescaled_points)\n",
    "    return rescaled_pose\n",
    "    \n",
    "\n",
    "def find_distance(pt1, pt2):\n",
    "    return np.sqrt((pt2.x - pt1.x)**2 + (pt2.y - pt1.y)**2)\n",
    "\n",
    "    \n",
    "def new_extract_features(pose, central_point_idx, specific_points):\n",
    "    assert central_point_idx not in specific_points\n",
    "    \n",
    "    rescaled_pose = rescale_pose(pose)\n",
    "    central_point = rescaled_pose.points[central_point_idx]\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    for current_points_idx in specific_points:\n",
    "        current_point = rescaled_pose.points[current_points_idx]\n",
    "\n",
    "        dx = central_point.x - current_point.x\n",
    "        dy = central_point.y - current_point.y\n",
    "    \n",
    "        features.append(dx)\n",
    "        features.append(dy)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "import cv2\n",
    "    \n",
    "from time import time\n",
    "    \n",
    "from src.PoseExtractor import PoseExtractor\n",
    "from src.visualization import *\n",
    "\n",
    "from src.data_processing.pose_utils import * \n",
    "\n",
    "def get_biggest_pose(poses):\n",
    "    max_distance = -1\n",
    "    biggest_pose = None\n",
    "    if len(poses):\n",
    "        for pose in poses:\n",
    "            pose_key_point1 = pose.points[1]\n",
    "            pose_key_point2 = pose.points[8]\n",
    "            if all(pose_key_point1.int_xy) and all(pose_key_point2.int_xy):\n",
    "                distance = get_distance_between_points(pose_key_point1, pose_key_point2)\n",
    "                if distance >= max_distance:\n",
    "                    max_distance = distance\n",
    "                    biggest_pose = pose\n",
    "        return biggest_pose\n",
    "    \n",
    "    \n",
    "    \n",
    "def signed_features_extraction(pose, central_point_idx, specific_points=None):\n",
    "    assert specific_points is not None, \"Udefined specific points!\"\n",
    "    central_point = pose.points[central_point_idx]\n",
    "    if central_point.x > 0 and central_point.y > 0: # if point detected. (if (0, 0) - hidden point)\n",
    "        xs = [pt.x for pt in pose.points]\n",
    "        ys = [pt.y for pt in pose.points]\n",
    "        \n",
    "        dxs = [central_point.x - x for x in xs]\n",
    "        dys = [central_point.y - y for y in ys]\n",
    "        \n",
    "        for i, (dx, dy) in enumerate(zip(dxs, dys)):\n",
    "            if dx == central_point.x and dy == central_point.y and i in specific_points:\n",
    "                return None\n",
    "\n",
    "        dxs -= np.mean(dxs)\n",
    "        dxs /= np.std(dxs)\n",
    "        dys -= np.mean(dys)\n",
    "        dys /= np.std(dys)\n",
    "                \n",
    "        features = []\n",
    "        for point_idx in specific_points:\n",
    "            features.append(dxs[point_idx])\n",
    "            features.append(dys[point_idx])\n",
    "        return np.array(features)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "cam = cv2.VideoCapture(0)\n",
    "pose_extractor = PoseExtractor()\n",
    "\n",
    "# top_pose_points = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 15, 16, 17, 18]\n",
    "top_pose_points = [0, 2, 3, 4, 5, 6, 7, 8, 9, 12, 15, 16, 17, 18]\n",
    "\n",
    "central_point_idx = 1\n",
    "normalize_features = False\n",
    "ignore_nan = True\n",
    "pose_rescaling = True\n",
    "\n",
    "\n",
    "times_list = []\n",
    "counter = 0\n",
    "\n",
    "while True and counter < 100:\n",
    "    ret, img = cam.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    img_to_show = img.copy()\n",
    "    poses = pose_extractor.extract_poses_from_image(img)\n",
    "    biggest_pose = get_biggest_pose(poses)\n",
    "    img_to_show[:35, :250] = (255, 255, 255)\n",
    "    img_to_show[-30:, -100:] = (0, 0, 0)\n",
    "    cv2.putText(img_to_show, \"SVM\", (570, 475), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    if biggest_pose is not None:\n",
    "\n",
    "        signed_f = signed_features_extraction(biggest_pose, central_point_idx, specific_points=top_pose_points)\n",
    "\n",
    "        features = new_extract_features(biggest_pose, 1, top_pose_points)\n",
    "        if features is not None and not any(np.isnan(features)):\n",
    "#             prediction_result = clf.predict(features.reshape(1, -1))\n",
    "#             gesture = decode_labels_dict[prediction_result[0]]\n",
    "            start_time = time()\n",
    "            gesture = predict(model5, features)\n",
    "            times_list.append(time() - start_time)\n",
    "            counter += 1\n",
    "            cv2.putText(img_to_show, gesture, (5, 28), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 40, 50), 2)\n",
    "\n",
    "        draw_pose(img_to_show, biggest_pose)    \n",
    "    cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"img\", img_to_show)\n",
    "    k = cv2.waitKey(10)\n",
    "    if k & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model5.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model5.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001726830005645752"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_list) # NN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
